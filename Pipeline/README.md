# 🏭 Producer–Workers–Consumer Pipeline (Assignment 4)

This program simulates a **pipeline of 101 processes** in C:  
- **Producer** generates data (work items).  
- **99 Worker processes** each apply a unique transformation/tool.  
- **Consumer** collects the processed data and classifies the output.  

It demonstrates the **assembly-line concept** in parallel programming, where multiple stages of computation are executed concurrently.

---

## 📘 Problem Description
- **Input**: Sequence of numbers generated by the Producer.  
- **Task**: Pass numbers through 99 sequential Worker processes, each modifying the data.  
- **Output**: Final transformed results collected and printed by the Consumer.  

---

## 🧠 Key Concepts
- **Pipeline Parallelism** → Breaking computation into stages, with each stage handled by a separate process.  
- **Concurrency** → Multiple work items flow through the pipeline at once, improving throughput.  
- **DSA Connection** → Models real-world **stream processing** and relates to **queues / scheduling problems** in algorithms.  

---

## 📊 Example Flow
Producer → Worker 1 → Worker 2 → ... → Worker 99 → Consumer


Each worker modifies the `message.current` value, then passes it to the next process. The Consumer classifies the final output.

---

## ⚡ Efficiency
- Sequential execution: Each work item would pass through all tools **one by one**.  
- Parallel pipeline: Multiple work items can be **in different stages at the same time**, increasing throughput.  
- Analogy: **Assembly line in factories** → while one item is being painted, another is being polished, etc.  

---

## 🛠 How to Run
```bash
gcc assignment4.c -o pipeline
./pipeline

